{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline \n",
    "按照如下的指导要求，搭建你的机器学习管道。\n",
    "### 1. 导入与加载\n",
    "- 导入 Python 库\n",
    "- 使用 [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html) 从数据库中加载数据集\n",
    "- 定义特征变量X 和目标变量 Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T07:52:52.807548Z",
     "start_time": "2020-08-02T07:52:44.364065Z"
    }
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import sqlite3\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T07:52:58.630881Z",
     "start_time": "2020-08-02T07:52:56.236744Z"
    }
   },
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine('sqlite:///InsertDatabaseName.db')\n",
    "df = pd.read_sql_table(table_name='InsertTableName',con=engine,index_col='id')\n",
    "X = df['message']\n",
    "Y = df[['related', 'request', 'offer',\n",
    "       'aid_related', 'medical_help', 'medical_products', 'search_and_rescue',\n",
    "       'security', 'military', 'child_alone', 'water', 'food', 'shelter',\n",
    "       'clothing', 'money', 'missing_people', 'refugees', 'death', 'other_aid',\n",
    "       'infrastructure_related', 'transport', 'buildings', 'electricity',\n",
    "       'tools', 'hospitals', 'shops', 'aid_centers', 'other_infrastructure',\n",
    "       'weather_related', 'floods', 'storm', 'fire', 'earthquake', 'cold',\n",
    "       'other_weather', 'direct_report']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 编写分词函数，开始处理文本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T07:53:42.355382Z",
     "start_time": "2020-08-02T07:53:02.278090Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\tendays\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tendays\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\tendays\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def tokenize(text):\n",
    "    text = re.sub(r\"[^z-zA-Z0-9]\",\" \" ,text.lower())    \n",
    "    tokens = word_tokenize(text)    \n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]    \n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 创建机器学习管道 \n",
    "这个机器学习管道应该接收 `message` 列作输入，输出分类结果，分类结果属于该数据集中的 36 个类。你会发现 [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) 在预测多目标变量时很有用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T07:54:39.450648Z",
     "start_time": "2020-08-02T07:54:37.900559Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class StartingVerbExtractor(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def starting_verb(self, text):\n",
    "        sentence_list = nltk.sent_tokenize(text)\n",
    "        for sentence in sentence_list:\n",
    "            pos_tags = nltk.pos_tag(tokenize(sentence))\n",
    "            first_word, first_tag = pos_tags[0]\n",
    "            if first_tag in ['VB', 'VBP'] or first_word == 'RT':\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_tagged = pd.Series(X).apply(self.starting_verb)\n",
    "        return pd.DataFrame(X_tagged)\n",
    "\n",
    "\n",
    "pipeline = Pipeline([\n",
    "        ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "        ('tfidf', TfidfTransformer()),\n",
    "        ('clf', MultiOutputClassifier( DecisionTreeClassifier(random_state =42), n_jobs = -1))\n",
    "         ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 训练管道\n",
    "- 将数据分割成训练和测试集\n",
    "- 训练管道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T07:55:03.370016Z",
     "start_time": "2020-08-02T07:54:42.764837Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "10084    1\n",
      "2269     1\n",
      "22619    1\n",
      "19207    1\n",
      "18112    1\n",
      "Name: related, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     1\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: request, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: offer, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     1\n",
      "22619    0\n",
      "19207    0\n",
      "18112    1\n",
      "Name: aid_related, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: medical_help, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: medical_products, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: search_and_rescue, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: security, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: military, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: child_alone, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     1\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: water, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     1\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: food, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     1\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: shelter, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: clothing, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: money, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: missing_people, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: refugees, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: death, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    1\n",
      "Name: other_aid, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: infrastructure_related, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: transport, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: buildings, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: electricity, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: tools, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: hospitals, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: shops, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: aid_centers, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: other_infrastructure, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    1\n",
      "Name: weather_related, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    1\n",
      "Name: floods, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: storm, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: fire, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: earthquake, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: cold, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     0\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: other_weather, dtype: int32\n",
      "id\n",
      "10084    0\n",
      "2269     1\n",
      "22619    0\n",
      "19207    0\n",
      "18112    0\n",
      "Name: direct_report, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "\n",
    "X_train,X_test ,Y_train ,Y_test =train_test_split(X,Y)\n",
    "\n",
    "pipeline.fit(X_train ,Y_train)\n",
    "Y_pred=pipeline.predict(X_test)\n",
    "\n",
    "Y_test.columns\n",
    "\n",
    "Y_pred=pd.DataFrame(Y_pred,columns=['related', 'request', 'offer', 'aid_related', 'medical_help',\n",
    "       'medical_products', 'search_and_rescue', 'security', 'military',\n",
    "       'child_alone', 'water', 'food', 'shelter', 'clothing', 'money',\n",
    "       'missing_people', 'refugees', 'death', 'other_aid',\n",
    "       'infrastructure_related', 'transport', 'buildings', 'electricity',\n",
    "       'tools', 'hospitals', 'shops', 'aid_centers', 'other_infrastructure',\n",
    "       'weather_related', 'floods', 'storm', 'fire', 'earthquake', 'cold',\n",
    "       'other_weather', 'direct_report']).astype('int')\n",
    "Y_pred['related'].head()\n",
    "Y_test=pd.DataFrame(Y_test).astype('int')\n",
    "\n",
    "for i in Y_test.columns:\n",
    "    print(Y_test[i].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 测试模型\n",
    "报告数据集中每个输出类别的 f1 得分、准确度和召回率。你可以对列进行遍历，并对每个元素调用 sklearn 的 `classification_report`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T07:55:08.850329Z",
     "start_time": "2020-08-02T07:55:08.625317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "related\n",
      "f1_scroe: 0.30460787313301513\n",
      "precision_score: 0.3486612350139884\n",
      "recall_score: 0.3356308736275691 \n",
      "\n",
      "request\n",
      "f1_scroe: 0.4761998421531879\n",
      "precision_score: 0.5704669590582585\n",
      "recall_score: 0.5072673411020908 \n",
      "\n",
      "offer\n",
      "f1_scroe: 0.4987763842153564\n",
      "precision_score: 0.49786259541984734\n",
      "recall_score: 0.4996935335580754 \n",
      "\n",
      "aid_related\n",
      "f1_scroe: 0.4928291172131446\n",
      "precision_score: 0.5943255727340443\n",
      "recall_score: 0.5398720774408576 \n",
      "\n",
      "medical_help\n",
      "f1_scroe: 0.4870827364527284\n",
      "precision_score: 0.5037712446783548\n",
      "recall_score: 0.5005368744458263 \n",
      "\n",
      "medical_products\n",
      "f1_scroe: 0.5072770885067814\n",
      "precision_score: 0.5505591002205086\n",
      "recall_score: 0.5090944167993117 \n",
      "\n",
      "search_and_rescue\n",
      "f1_scroe: 0.5004703560820016\n",
      "precision_score: 0.5176942135273201\n",
      "recall_score: 0.5029291758356911 \n",
      "\n",
      "security\n",
      "f1_scroe: 0.5035763609233651\n",
      "precision_score: 0.5415189486552567\n",
      "recall_score: 0.5037657448884553 \n",
      "\n",
      "military\n",
      "f1_scroe: 0.5019926373327108\n",
      "precision_score: 0.5403056655354449\n",
      "recall_score: 0.5047032698072216 \n",
      "\n",
      "child_alone\n",
      "f1_scroe: 1.0\n",
      "precision_score: 1.0\n",
      "recall_score: 1.0 \n",
      "\n",
      "water\n",
      "f1_scroe: 0.49519482573412676\n",
      "precision_score: 0.5324020939806232\n",
      "recall_score: 0.5038896095867424 \n",
      "\n",
      "food\n",
      "f1_scroe: 0.4908243718448775\n",
      "precision_score: 0.5408585327694526\n",
      "recall_score: 0.506012576263382 \n",
      "\n",
      "shelter\n",
      "f1_scroe: 0.5151277081268026\n",
      "precision_score: 0.6229465986920026\n",
      "recall_score: 0.5182361572820297 \n",
      "\n",
      "clothing\n",
      "f1_scroe: 0.49565217391304345\n",
      "precision_score: 0.49220541036221915\n",
      "recall_score: 0.49914755114693116 \n",
      "\n",
      "money\n",
      "f1_scroe: 0.5268358085808581\n",
      "precision_score: 0.5800978656368934\n",
      "recall_score: 0.5183010928735471 \n",
      "\n",
      "missing_people\n",
      "f1_scroe: 0.5207382707382707\n",
      "precision_score: 0.5779832874757974\n",
      "recall_score: 0.5131175220268093 \n",
      "\n",
      "refugees\n",
      "f1_scroe: 0.49843397106859544\n",
      "precision_score: 0.5156246136499631\n",
      "recall_score: 0.5022773386960173 \n",
      "\n",
      "death\n",
      "f1_scroe: 0.5271946463656308\n",
      "precision_score: 0.5747671877227158\n",
      "recall_score: 0.5206545897629975 \n",
      "\n",
      "other_aid\n",
      "f1_scroe: 0.47403688434385777\n",
      "precision_score: 0.5093804228588096\n",
      "recall_score: 0.5009009689374819 \n",
      "\n",
      "infrastructure_related\n",
      "f1_scroe: 0.4863029241118977\n",
      "precision_score: 0.4881173513392556\n",
      "recall_score: 0.4979274448439625 \n",
      "\n",
      "transport\n",
      "f1_scroe: 0.49780733656634124\n",
      "precision_score: 0.5468346394641216\n",
      "recall_score: 0.5042273732047371 \n",
      "\n",
      "buildings\n",
      "f1_scroe: 0.49688093161207764\n",
      "precision_score: 0.5252840036843721\n",
      "recall_score: 0.5032447959147487 \n",
      "\n",
      "electricity\n",
      "f1_scroe: 0.4939386919928963\n",
      "precision_score: 0.48951637588001223\n",
      "recall_score: 0.4984416393953561 \n",
      "\n",
      "tools\n",
      "f1_scroe: 0.4983543819364715\n",
      "precision_score: 0.4968711843711844\n",
      "recall_score: 0.49984646092430524 \n",
      "\n",
      "hospitals\n",
      "f1_scroe: 0.4969683014813109\n",
      "precision_score: 0.49487924182207277\n",
      "recall_score: 0.4990750732233698 \n",
      "\n",
      "shops\n",
      "f1_scroe: 0.4986613631148168\n",
      "precision_score: 0.4975576247901084\n",
      "recall_score: 0.499770009199632 \n",
      "\n",
      "aid_centers\n",
      "f1_scroe: 0.4966978958685302\n",
      "precision_score: 0.4944954128440367\n",
      "recall_score: 0.49892008639308855 \n",
      "\n",
      "other_infrastructure\n",
      "f1_scroe: 0.4958101652439502\n",
      "precision_score: 0.5186534724353073\n",
      "recall_score: 0.5023109173819318 \n",
      "\n",
      "weather_related\n",
      "f1_scroe: 0.5276727873691913\n",
      "precision_score: 0.6320223128280757\n",
      "recall_score: 0.5462671704537698 \n",
      "\n",
      "floods\n",
      "f1_scroe: 0.5121716170582843\n",
      "precision_score: 0.5676766320876208\n",
      "recall_score: 0.5147792073357853 \n",
      "\n",
      "storm\n",
      "f1_scroe: 0.5049244583063536\n",
      "precision_score: 0.5630336904207421\n",
      "recall_score: 0.5121550187473108 \n",
      "\n",
      "fire\n",
      "f1_scroe: 0.5075704045512757\n",
      "precision_score: 0.5222698218414252\n",
      "recall_score: 0.5055377890694189 \n",
      "\n",
      "earthquake\n",
      "f1_scroe: 0.5630013991753807\n",
      "precision_score: 0.6834446022727273\n",
      "recall_score: 0.5483765107040619 \n",
      "\n",
      "cold\n",
      "f1_scroe: 0.5153282419193088\n",
      "precision_score: 0.5561069947341442\n",
      "recall_score: 0.5107403555990538 \n",
      "\n",
      "other_weather\n",
      "f1_scroe: 0.5008283657779738\n",
      "precision_score: 0.525029021784477\n",
      "recall_score: 0.5050838168923275 \n",
      "\n",
      "direct_report\n",
      "f1_scroe: 0.47138614988773203\n",
      "precision_score: 0.556123717749456\n",
      "recall_score: 0.5065598488564318 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, classification_report, confusion_matrix\n",
    "\n",
    "for i in Y_test.columns:\n",
    "    print(i)\n",
    "    print('f1_scroe:',f1_score(Y_test[i], Y_pred[i], average='macro'))\n",
    "    print('precision_score:',precision_score(Y_test[i], Y_pred[i], average=\"macro\"))\n",
    "    print('recall_score:',recall_score(Y_test[i], Y_pred[i], average=\"macro\"),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 优化模型\n",
    "使用网格搜索来找到最优的参数组合。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-02T07:59:03.456748Z",
     "start_time": "2020-08-02T07:59:03.444747Z"
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-674e9fdd6354>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-13-674e9fdd6354>\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    cv = GridSearchCV(pipeline, parameters)\u001b[0m\n\u001b[1;37m     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {\n",
    "        'vect__ngram_range': ((1, 1), (1, 2)),\n",
    "        'vect__max_df': (0.5, 0.75, 1.0),\n",
    "        'vect__max_features': (None, 5000, 10000),\n",
    "        'tfidf__use_idf': (True, False)}\n",
    "\n",
    "cv = GridSearchCV(pipeline, parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 测试模型\n",
    "打印微调后的模型的精确度、准确率和召回率。  \n",
    "\n",
    "因为本项目主要关注代码质量、开发流程和管道技术，所有没有模型性能指标的最低要求。但是，微调模型提高精确度、准确率和召回率可以让你的项目脱颖而出——特别是让你的简历更出彩。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit=cv.fit(X_train, Y_train)\n",
    "print(\"\\nBest Parameters:\", fit.best_params_)\n",
    "Y_pred=fit.best_estimator_.predict(X_test)\n",
    "\n",
    "Y_pred=pd.DataFrame(Y_pred,columns=['related', 'request', 'offer', 'aid_related', 'medical_help',\n",
    "       'medical_products', 'search_and_rescue', 'security', 'military',\n",
    "       'child_alone', 'water', 'food', 'shelter', 'clothing', 'money',\n",
    "       'missing_people', 'refugees', 'death', 'other_aid',\n",
    "       'infrastructure_related', 'transport', 'buildings', 'electricity',\n",
    "       'tools', 'hospitals', 'shops', 'aid_centers', 'other_infrastructure',\n",
    "       'weather_related', 'floods', 'storm', 'fire', 'earthquake', 'cold',\n",
    "       'other_weather', 'direct_report']).astype('int')\n",
    "Y_test=pd.DataFrame(Y_test).astype('int')\n",
    "for i in Y_test.columns:\n",
    "    print(i)\n",
    "    print('f1_scroe:',f1_score(Y_test[i], Y_pred[i], average='macro'))\n",
    "    print('precision_score:',precision_score(Y_test[i], Y_pred[i], average=\"macro\"))\n",
    "    print('recall_score:',recall_score(Y_test[i], Y_pred[i], average=\"macro\"),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 继续优化模型，比如：\n",
    "* 尝试其他的机器学习算法\n",
    "* 尝试除 TF-IDF 外其他的特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "def tokenize(text):\n",
    "    text = re.sub(r\"[^z-zA-Z0-9]\",\" \" ,text.lower())\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "\n",
    "def TextLengthExtractor(text):\n",
    "    txt_length = text.apply(len)\n",
    "    return txt_length\n",
    "    \n",
    "pipeline_fix = Pipeline([\n",
    "        ('features', FeatureUnion([\n",
    "            \n",
    "            ('text_pipeline', Pipeline([\n",
    "                ('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "                ('tfidf', TfidfTransformer())\n",
    "            ]))\n",
    "\n",
    "\n",
    "        ])),\n",
    "        ('clf', RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "pipeline_fix.fit(X_train,Y_train)\n",
    "Y_pred=pipeline_fix.predict(X_test)\n",
    "Y_pred=pd.DataFrame(Y_pred,columns=['related', 'request', 'offer', 'aid_related', 'medical_help',\n",
    "       'medical_products', 'search_and_rescue', 'security', 'military',\n",
    "       'child_alone', 'water', 'food', 'shelter', 'clothing', 'money',\n",
    "       'missing_people', 'refugees', 'death', 'other_aid',\n",
    "       'infrastructure_related', 'transport', 'buildings', 'electricity',\n",
    "       'tools', 'hospitals', 'shops', 'aid_centers', 'other_infrastructure',\n",
    "       'weather_related', 'floods', 'storm', 'fire', 'earthquake', 'cold',\n",
    "       'other_weather', 'direct_report']).astype('float')\n",
    "\n",
    "Y_test=Y_test.astype('float')\n",
    "\n",
    "for i in Y_test.columns:\n",
    "    print(i)\n",
    "    print('f1_scroe:',f1_score(Y_test[i], Y_pred[i], average='macro'))\n",
    "    print('precision_score:',precision_score(Y_test[i], Y_pred[i], average=\"macro\"))\n",
    "    print('recall_score:',recall_score(Y_test[i], Y_pred[i], average=\"macro\"),'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. 导出模型为 pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "from sklearn.externals import joblib\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "\n",
    "#1.保存成Python支持的文件格式Pickle\n",
    "\n",
    "#在当前目录下可以看到svm.pickle\n",
    "with open('pipeline_fix.pickle','wb') as fw:\n",
    "    pickle.dump(pipeline_fix,fw)\n",
    "#加载svm.pickle\n",
    "with open('pipeline_fix.pickle','rb') as fr:\n",
    "    new_pipeline_fix1 = pickle.load(fr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "使用资源 (Resources)文件里附带的模板文件编写脚本，运行上述步骤，创建一个数据库，并基于用户指定的新数据集输出一个模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
